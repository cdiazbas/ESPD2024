{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CME predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Coronal Mass Ejection (CME) throws magnetic flux and plasma from the Sun into interplanetary space. These eruptions are related to solar flares, wherein a flare unassociated with a CME is called a confined or compact flare. In general, the more energetic a flare, the more likely it is to be associated with a CME but this is not a rule. In this notebook, we will be predicting whether or not a flaring active region will also emit a CME using machine learning. This notebook and analysis are based on the work of [Bobra & Ilonidis, 2016](http://adsabs.harvard.edu/abs/2016ApJ...821..127B) and [Bobra & Manson, 2018](https://helioml.org/Introduction/title.html), with some new ideas. Please cite these sources if you use this notebook for your research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this prediction problem, we'll then ascribe each active region to one of two classes:\n",
    "\n",
    "1. The positive class contains flaring active regions that did produce a CME. \n",
    "\n",
    "2. The negative class contains flaring active regions that did not produce a CME. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create our CME predictor we need to gather our training dataset: \n",
    "\n",
    "1. CME data from SOHO/LASCO and STEREO/SECCHI coronographs, which can be accessed from the `Database Of Notifications, Knowledge, Information` [DONKI database](http://kauai.ccmc.gsfc.nasa.gov/DONKI/). This tells us if an active region has produced a CME or not.\n",
    "\n",
    "2. Flare data from the GOES flare catalog at NOAA, which can be accessed with the `sunkit_instruments` library, a SunPy affiliated package for solar instrument-specific tools. This tells us if an active region produced a flare or not.\n",
    "\n",
    "3. Active region data from the Solar Dynamics Observatory's `Helioseismic and Magnetic Imager instrument` (HMI), which can be accessed from the [JSOC database](http://jsoc.stanford.edu/) via a JSON API. This gives us the features characterizing each active region `SHARP` – Space-Weather HMI Active Region Patches [Bobra et al., 2014](http://link.springer.com/article/10.1007%2Fs11207-014-0529-3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Gathering data for the positive class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll import some modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import requests\n",
    "import urllib\n",
    "import json\n",
    "from datetime import datetime as dt_obj\n",
    "from datetime import timedelta\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "# Sunpy\n",
    "try:\n",
    "    import sunpy\n",
    "    from sunpy.time import TimeRange\n",
    "except ImportError:\n",
    "    %pip install sunpy\n",
    "    from sunpy.time import TimeRange\n",
    "\n",
    "# Lime library\n",
    "try:\n",
    "    import lime\n",
    "    import lime.lime_tabular\n",
    "except ImportError:\n",
    "    %pip install lime\n",
    "    import lime\n",
    "    import lime.lime_tabular\n",
    "    \n",
    "# Sunkit-instruments\n",
    "try:\n",
    "    import sunkit_instruments\n",
    "except ImportError:\n",
    "    %pip install sunkit_instruments\n",
    "    import sunkit_instruments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first query the [DONKI database](http://kauai.ccmc.gsfc.nasa.gov/DONKI/) to get the data associated with the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request the data\n",
    "baseurl = \"https://kauai.ccmc.gsfc.nasa.gov/DONKI/WS/get/FLR?\"\n",
    "t_start = \"2010-05-01\"\n",
    "t_end = \"2024-03-01\"\n",
    "url = baseurl+\"startDate=\"+t_start+\"&endDate=\"+t_end\n",
    "print('[INFO] requesting data from', url)\n",
    "\n",
    "flag_for_fulldataset = False if t_end.split('-')[0] < '2018' else True\n",
    "flag_for_fulldataset = True\n",
    "print('[INFO] flag_for_fulldataset:', flag_for_fulldataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "df = pd.read_json(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.- we will focus only on the strongest flares: M and X class\n",
    "# 2.- we will drop the rows that aren't linked to CME events\n",
    "events_list = df.loc[df['classType'].str.contains(\"M|X\") & df['linkedEvents'].apply(lambda x: any('CME' in i['activityID'] for i in x) if x is not None else False)]\n",
    "\n",
    "# Drop the most of columns for a better visualization after the filtering\n",
    "events_list = events_list.drop(columns=['flrID','linkedEvents','instruments','beginTime','endTime','link'])\n",
    "events_list = events_list.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len_events = events_list.shape[0]\n",
    "print(\"There are\", len_events, \"events in the list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the `peakTime` column in the `events_list` dataframe from a string into a datetime object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tai_string(tstr):\n",
    "    year = int(tstr[:4])\n",
    "    month = int(tstr[5:7])\n",
    "    day = int(tstr[8:10])\n",
    "    hour = int(tstr[11:13])\n",
    "    minute = int(tstr[14:16])\n",
    "    return dt_obj(year, month, day, hour, minute)\n",
    "\n",
    "\n",
    "for i in range(events_list.shape[0]):\n",
    "    events_list.loc[i, 'peakTime'] = parse_tai_string(events_list.loc[i, 'peakTime'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to improve the data quality. We need to check 3 cases:\n",
    "1. The DONKI database does not have the active region number.\n",
    "2. The DONKI database has the active region number but it is not the correct one.\n",
    "3. The DONKI database has the peak time of the flare but it is not the correct one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for Case 1: In this case, the CME and flare exist but NOAA active region number does not exist in the DONKI database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sunkit_instruments.goes_xrs\n",
    "\n",
    "# We will use the GOES flare database to find the missing NOAA active region numbers\n",
    "\n",
    "number_of_donki_mistakes = 0  # count the number of DONKI mistakes\n",
    "\n",
    "# Create a list to store the indices of the rows that will be dropped\n",
    "event_list_drops = []\n",
    "for i in range(events_list.shape[0]):\n",
    "    \n",
    "    # print(events_list.loc[i]['activeRegionNum'])\n",
    "    # If the active region number is NaN, we will find the missing NOAA active region number\n",
    "    if (np.isnan(events_list.loc[i]['activeRegionNum'])):\n",
    "        time = events_list.loc[i]['peakTime']\n",
    "        time_range = TimeRange(time, time)\n",
    "        # A string specifying a minimum GOES class for inclusion in the list, e.g., “M1”, “X2”.\n",
    "        listofresults =  sunkit_instruments.goes_xrs.get_goes_event_list(time_range, 'M1')\n",
    "        \n",
    "        if len(listofresults) < 0.5:\n",
    "            # When sunkit fails to find any event that day\n",
    "            print(time,events_list.loc[i]['classType'], \"has no match in the GOES flare database ; dropping row.\")\n",
    "            event_list_drops.append(i)\n",
    "            number_of_donki_mistakes += 1\n",
    "            continue\n",
    "        \n",
    "        if (listofresults[0]['noaa_active_region'] == 0):\n",
    "            print(time,events_list.loc[i]['activeRegionNum'], events_list.loc[i]\n",
    "                  ['classType'], \"has no match in the GOES flare database ; dropping row.\")\n",
    "            event_list_drops.append(i)\n",
    "            number_of_donki_mistakes += 1\n",
    "            continue\n",
    "        else:\n",
    "            print(\"Missing NOAA number:\", events_list.loc[i]['activeRegionNum'], events_list.loc[i]['classType'],\n",
    "                  events_list['peakTime'].iloc[i], \"should be\", listofresults[0]['noaa_active_region'], \"; changing now.\")\n",
    "            events_list.loc[i, 'activeRegionNum'] = listofresults[0]['noaa_active_region']\n",
    "            number_of_donki_mistakes += 1\n",
    "\n",
    "# Drop the rows for which there is no active region number in both the DONKI and GOES flare databases\n",
    "events_list = events_list.drop(event_list_drops)\n",
    "events_list = events_list.reset_index(drop=True)\n",
    "print('There are', number_of_donki_mistakes, 'DONKI mistakes so far.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we grab all the data from the GOES database in preparation for checking Cases 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grab all the data from the GOES database\n",
    "time_range = TimeRange(t_start, t_end)\n",
    "listofresults = sunkit_instruments.goes_xrs.get_goes_event_list(time_range, 'M1')\n",
    "print('Grabbed all the GOES data; there are', len(listofresults), 'events.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for Case 2: In this case, the NOAA active region number is wrong in the DONKI database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Case 2: NOAA active region number is wrong in DONKI database\n",
    "\n",
    "# collect all the peak flares times in the NOAA database\n",
    "peak_times_noaa = [item[\"peak_time\"] for item in listofresults]\n",
    "\n",
    "for i in range(events_list.shape[0]):\n",
    "    # check if a particular DONKI flare peak time is also in the NOAA database\n",
    "    peak_time_donki = events_list['peakTime'].iloc[i]\n",
    "    if peak_time_donki in peak_times_noaa:\n",
    "        index = peak_times_noaa.index(peak_time_donki)\n",
    "    else:\n",
    "        continue\n",
    "    # ignore NOAA active region numbers equal to zero\n",
    "    if (listofresults[index]['noaa_active_region'] == 0):\n",
    "        continue\n",
    "    # if yes, check if the DONKI and NOAA active region numbers match up for this peak time\n",
    "    # if they don't, flag this peak time and replace the DONKI number with the NOAA number\n",
    "    if (listofresults[index]['noaa_active_region'] != int(events_list['activeRegionNum'].iloc[i])):\n",
    "        print('Messed up NOAA number:', int(events_list['activeRegionNum'].iloc[i]), events_list['classType'].iloc[i],\n",
    "              events_list['peakTime'].iloc[i], \"should be\", listofresults[index]['noaa_active_region'], \"; changing now.\")\n",
    "        events_list.loc[i, 'activeRegionNum'] = listofresults[index]['noaa_active_region']\n",
    "        number_of_donki_mistakes += 1\n",
    "print('There are', number_of_donki_mistakes, 'DONKI mistakes so far.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for Case 3: In this case, the flare peak time is wrong in the DONKI database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 3: The flare peak time is wrong in the DONKI database.\n",
    "\n",
    "# create an empty array to hold row numbers to drop at the end\n",
    "event_list_drops = []\n",
    "\n",
    "active_region_numbers_noaa = [item[\"noaa_active_region\"]\n",
    "                              for item in listofresults]\n",
    "flare_classes_noaa = [item[\"goes_class\"] for item in listofresults]\n",
    "\n",
    "for i in range(events_list.shape[0]):\n",
    "    # check if a particular DONKI flare peak time is also in the NOAA database\n",
    "    peak_time_donki = events_list['peakTime'].iloc[i]\n",
    "    if not peak_time_donki in peak_times_noaa:\n",
    "        active_region_number_donki = int(\n",
    "            events_list.loc[i,'activeRegionNum'])\n",
    "        flare_class_donki = events_list['classType'].iloc[i]\n",
    "        flare_class_indices = [i for i, x in enumerate(\n",
    "            flare_classes_noaa) if x == flare_class_donki]\n",
    "        active_region_indices = [i for i, x in enumerate(\n",
    "            active_region_numbers_noaa) if x == active_region_number_donki]\n",
    "        common_indices = list(\n",
    "            set(flare_class_indices).intersection(active_region_indices))\n",
    "        if common_indices:\n",
    "            print(\"Messed up time:\", int(events_list['activeRegionNum'].iloc[i]), events_list.loc[i,'classType'],\n",
    "                  events_list.loc[i,'peakTime'], \"should be\", peak_times_noaa[common_indices[0]], \"; changing now.\")\n",
    "            events_list.loc[i, 'peakTime'] = peak_times_noaa[common_indices[0]]\n",
    "            number_of_donki_mistakes += 1\n",
    "        if not common_indices:\n",
    "            print(\"DONKI flare peak time\",\n",
    "                  events_list.loc[i, 'peakTime'], \"has no match; dropping row.\")\n",
    "            event_list_drops.append(i)\n",
    "            number_of_donki_mistakes += 1\n",
    "\n",
    "# Drop the rows for which the NOAA active region number and flare class associated with\n",
    "# the messed-up flare peak time in the DONKI database has no match in the GOES flare database\n",
    "events_list = events_list.drop(event_list_drops)\n",
    "events_list = events_list.reset_index(drop=True)\n",
    "\n",
    "# Create a list of corrected flare peak times\n",
    "peak_times_donki = [events_list.loc[i, 'peakTime']\n",
    "                    for i in range(events_list.shape[0])]\n",
    "\n",
    "\n",
    "print('There are', number_of_donki_mistakes, 'DONKI mistakes so far.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our final table of events that fall into the positive class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "events_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's query the JSOC database to see if there are active region parameters at the time of the flare. First read the following file to map NOAA active region numbers to HARPNUMs (a HARP, or an HMI Active Region Patch, is the preferred numbering system for the HMI active regions as they appear in the magnetic field data before NOAA observes them in white light):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = pd.read_csv(\n",
    "    'http://jsoc.stanford.edu/doc/data/hmi/harpnum_to_noaa/all_harps_with_noaa_ars.txt', sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's determine at which time we'd like to predict CMEs. In general, many people try to predict a CME either 24 or 48 hours before it happens. We can report both in this study by setting a variable called `timedelayvariable`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timedelayvariable = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll convert subtract `timedelayvariable` from the GOES Peak Time and re-format the datetime object into a string that JSOC can understand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_rec = [(events_list['peakTime'].iloc[i] - timedelta(hours=timedelayvariable)\n",
    "          ).strftime('%Y.%m.%d_%H:%M_TAI') for i in range(events_list.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can grab the SDO data from the JSOC database by executing the JSON queries. The SHARP parameters are calculated every 12 minutes during an AR lifetime. We are selecting data that satisfies several criteria: The data has to be [1] disambiguated with a version of the disambiguation module greater than 1.1, [2] taken while the orbital velocity of the spacecraft is less than 3500 m/s, [3] of a high quality, and [4] within 70 degrees of central meridian. If the data pass all these tests, they are stuffed into one of two lists: one for the positive class (called CME_data) and one for the negative class (called no_CME_data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_the_jsoc_data(event_count, t_rec):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    event_count: number of events \n",
    "                 int\n",
    "\n",
    "    t_rec:       list of times, one associated with each event in event_count\n",
    "                 list of strings in JSOC format ('%Y.%m.%d_%H:%M_TAI')\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    catalog_data = []\n",
    "    classification = []\n",
    "\n",
    "    for i in range(event_count):\n",
    "\n",
    "        print(\"=====\", i, \"=====\")\n",
    "        # next match NOAA_ARS to HARPNUM\n",
    "        idx = answer[answer['NOAA_ARS'].str.contains(\n",
    "            str(int(listofactiveregions[i])))]\n",
    "\n",
    "        # if there's no HARPNUM, quit\n",
    "        if (idx.empty == True):\n",
    "            print('skip: there are no matching HARPNUMs for',\n",
    "                  str(int(listofactiveregions[i])))\n",
    "            continue\n",
    "\n",
    "        # construct jsoc_info queries and query jsoc database; we are querying for 25 keywords\n",
    "        url = \"http://jsoc.stanford.edu/cgi-bin/ajax/jsoc_info?ds=hmi.sharp_720s[\"+str(\n",
    "            idx.HARPNUM.values[0])+\"][\"+t_rec[i]+\"][? (CODEVER7 !~ '1.1 ') and (abs(OBS_VR)< 3500) and (QUALITY<65536) ?]&op=rs_list&key=USFLUX,MEANGBT,MEANJZH,MEANPOT,SHRGT45,TOTUSJH,MEANGBH,MEANALP,MEANGAM,MEANGBZ,MEANJZD,TOTUSJZ,SAVNCPP,TOTPOT,MEANSHR,AREA_ACR,R_VALUE,ABSNJZH\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # if there's no response at this time, quit\n",
    "        if response.status_code != 200:\n",
    "            print('skip: cannot successfully get an http response')\n",
    "            continue\n",
    "\n",
    "        # read the JSON output\n",
    "        data = response.json()\n",
    "\n",
    "        # if there are no data at this time, quit\n",
    "        if data['count'] == 0:\n",
    "            print('skip: there are no data for HARPNUM',\n",
    "                  idx.HARPNUM.values[0], 'at time', t_rec[i])\n",
    "            continue\n",
    "\n",
    "        # check to see if the active region is too close to the limb\n",
    "        # we can compute the latitude of an active region in stonyhurst coordinates as follows:\n",
    "        # latitude_stonyhurst = CRVAL1 - CRLN_OBS\n",
    "        # for this we have to query the CEA series (but above we queried the other series as the CEA series does not have CODEVER5 in it)\n",
    "\n",
    "        url = \"http://jsoc.stanford.edu/cgi-bin/ajax/jsoc_info?ds=hmi.sharp_cea_720s[\"+str(\n",
    "            idx.HARPNUM.values[0])+\"][\"+t_rec[i]+\"][? (abs(OBS_VR)< 3500) and (QUALITY<65536) ?]&op=rs_list&key=CRVAL1,CRLN_OBS\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # if there's no response at this time, quit\n",
    "        if response.status_code != 200:\n",
    "            print('skip: failed to find CEA JSOC data for HARPNUM',\n",
    "                  idx.HARPNUM.values[0], 'at time', t_rec[i])\n",
    "            continue\n",
    "\n",
    "        # read the JSON output\n",
    "        latitude_information = response.json()\n",
    "\n",
    "        # if there are no data at this time, quit\n",
    "        if latitude_information['count'] == 0:\n",
    "            print('skip: there are no data for HARPNUM',\n",
    "                  idx.HARPNUM.values[0], 'at time', t_rec[i])\n",
    "            continue\n",
    "\n",
    "        CRVAL1 = float(latitude_information['keywords'][0]['values'][0])\n",
    "        CRLN_OBS = float(latitude_information['keywords'][1]['values'][0])\n",
    "        if (np.absolute(CRVAL1 - CRLN_OBS) > 70.0):\n",
    "            print('skip: latitude is out of range for HARPNUM',\n",
    "                  idx.HARPNUM.values[0], 'at time', t_rec[i])\n",
    "            continue\n",
    "\n",
    "        if ('MISSING' in str(data['keywords'])):\n",
    "            print('skip: there are some missing keywords for HARPNUM',\n",
    "                  idx.HARPNUM.values[0], 'at time', t_rec[i])\n",
    "            continue\n",
    "\n",
    "        print('accept NOAA Active Region number', str(int(\n",
    "            listofactiveregions[i])), 'and HARPNUM', idx.HARPNUM.values[0], 'at time', t_rec[i])\n",
    "\n",
    "        individual_flare_data = []\n",
    "        for j in range(18):\n",
    "            individual_flare_data.append(\n",
    "                float(data['keywords'][j]['values'][0]))\n",
    "\n",
    "        catalog_data.append(list(individual_flare_data))\n",
    "\n",
    "        single_class_instance = [idx.HARPNUM.values[0], str(\n",
    "            int(listofactiveregions[i])), listofgoesclasses[i], t_rec[i]]\n",
    "        classification.append(single_class_instance)\n",
    "\n",
    "    return catalog_data, classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we prepare the data to be fed into the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listofactiveregions = list(events_list['activeRegionNum'].values.flatten())\n",
    "listofgoesclasses = list(events_list['classType'].values.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And call the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "CME_data, positive_class = get_the_jsoc_data(events_list.shape[0], t_rec)\n",
    "\n",
    "# save the data\n",
    "if flag_for_fulldataset:\n",
    "    np.save('CME_data_full.npy', CME_data)\n",
    "    np.save('positive_class_full.npy', positive_class)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the number of events associated with the positive class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are\", len(CME_data), \"CME events in the positive class.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Gathering data for the negative class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To gather the examples for the negative class, we only need to:\n",
    "\n",
    "1. Query the GOES database for all the M- and X-class flares during our time of interest, and\n",
    "2. Select the ones that are not associated with a CME. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select peak times that belong to both classes\n",
    "all_peak_times = np.array([(listofresults[i]['peak_time'])\n",
    "                           for i in range(len(listofresults))])\n",
    "\n",
    "negative_class_possibilities = []\n",
    "counter_positive = 0\n",
    "counter_negative = 0\n",
    "for i in range(len(listofresults)):\n",
    "    this_peak_time = all_peak_times[i]\n",
    "    if (this_peak_time in peak_times_donki):\n",
    "        counter_positive += 1\n",
    "    else:\n",
    "        counter_negative += 1\n",
    "        this_instance = [listofresults[i]['noaa_active_region'],\n",
    "                         listofresults[i]['goes_class'], listofresults[i]['peak_time']]\n",
    "        negative_class_possibilities.append(this_instance)\n",
    "print(\"There are\", counter_positive, \"events in the positive class.\")\n",
    "print(\"There are\", counter_negative, \"events in the negative class.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we compute times that are one day before the flare peak time and convert it into a string that JSOC can understand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_rec = np.array([(negative_class_possibilities[i][2] - timedelta(hours=timedelayvariable)\n",
    "                   ).strftime('%Y.%m.%d_%H:%M_TAI') for i in range(len(negative_class_possibilities))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again, we query the JSOC database to see if these data are present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listofactiveregions = list(\n",
    "    negative_class_possibilities[i][0] for i in range(counter_negative))\n",
    "listofgoesclasses = list(\n",
    "    negative_class_possibilities[i][1] for i in range(counter_negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the data\n",
    "no_CME_data, negative_class = get_the_jsoc_data(counter_negative, t_rec)\n",
    "\n",
    "# save the data\n",
    "if flag_for_fulldataset:\n",
    "    np.save('no_CME_data.npy', no_CME_data)\n",
    "    np.save('negative_class.npy', negative_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the number of events associated with the negative class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are\", len(no_CME_data), \"no-CME events in the negative class.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of the data\n",
    "print(\"Number of features:\", len(CME_data[0]))\n",
    "\n",
    "# positive class\n",
    "print(\"Positive class:\")\n",
    "print(\"Number of events:\", len(CME_data))\n",
    "\n",
    "# negative class\n",
    "print(\"Negative class:\")\n",
    "print(\"Number of events:\", len(no_CME_data))\n",
    "\n",
    "# Ratio: negative class to positive class\n",
    "ratio = len(no_CME_data)/len(CME_data)\n",
    "print(\"Ratio of negative class to positive class:\", ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the features within a data set may be powerful for distinguishing between the positive and negative class, whereas others may be redundant or irrelevant. To identify features in the former category, we use a univariate feature selection method, which is implemented in the feature selection module of the scikit-learn library, for feature scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CME_data = np.array(CME_data)\n",
    "no_CME_data = np.array(no_CME_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the performance of the feature selection algorithm, we'll normalize each feature so that they lie within similar ranges. To do this, we subtract from every feature its median value and divide by its standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_the_data(flare_data):\n",
    "    flare_data = np.array(flare_data)\n",
    "    n_elements = flare_data.shape[0]\n",
    "    for j in range(flare_data.shape[1]):\n",
    "        standard_deviation_of_this_feature = np.std(flare_data[:, j])\n",
    "        median_of_this_feature = np.median(flare_data[:, j])\n",
    "        for i in range(n_elements):\n",
    "            flare_data[i, j] = (\n",
    "                flare_data[i, j] - median_of_this_feature) / (standard_deviation_of_this_feature)\n",
    "    return flare_data\n",
    "\n",
    "\n",
    "no_CME_data = normalize_the_data(no_CME_data)\n",
    "CME_data = normalize_the_data(CME_data)\n",
    "\n",
    "print(\"There are\", no_CME_data.shape[0], \"flares with no associated CMEs.\")\n",
    "print(\"There are\", CME_data.shape[0], \"flares with associated CMEs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the full data set:\n",
    "\n",
    "CME_data = np.load('CME_data.npy')\n",
    "positive_class = np.load('positive_class.npy')\n",
    "\n",
    "no_CME_data = np.load('no_CME_data.npy')\n",
    "negative_class = np.load('negative_class.npy')\n",
    "    \n",
    "\n",
    "prepare_student_data = True\n",
    "if prepare_student_data:\n",
    "\n",
    "    # Note: Extract 50 events and their corresponding features for testing later:\n",
    "    index_positive = np.random.choice(range(len(positive_class)), 25, replace=False)\n",
    "    index_negative = np.random.choice(range(len(negative_class)), 25, replace=False)\n",
    "    \n",
    "    # Extract the features and metadata for the selected events, and delete them from the full dataset\n",
    "    selected_features = np.concatenate((CME_data[index_positive], no_CME_data[index_negative]), axis=0)\n",
    "    selected_metadata = np.concatenate((positive_class[index_positive], negative_class[index_negative]), axis=0)\n",
    "    \n",
    "    # Shuffle the selected features and metadata to ensure they are mixed\n",
    "    shuffle_index = np.random.permutation(len(selected_features))\n",
    "    selected_features = selected_features[shuffle_index]\n",
    "    selected_metadata = selected_metadata[shuffle_index]\n",
    "    \n",
    "    # Save the selected features and metadata\n",
    "    np.save('student_target_features.npy', selected_features)\n",
    "    np.save('student_target_metadata.npy', selected_metadata)\n",
    "    \n",
    "    # remove the selected features from the full dataset\n",
    "    CME_data = np.delete(CME_data, index_positive, axis=0)\n",
    "    no_CME_data = np.delete(no_CME_data, index_negative, axis=0)\n",
    "    positive_class = np.delete(positive_class, index_positive, axis=0)\n",
    "    negative_class = np.delete(negative_class, index_negative, axis=0)\n",
    "    \n",
    "    # Save the new datasets\n",
    "    np.save('CME_data_.npy', CME_data)\n",
    "    np.save('positive_class_.npy', positive_class)\n",
    "    np.save('no_CME_data_.npy', no_CME_data)\n",
    "    np.save('negative_class_.npy', negative_class)\n",
    "\n",
    "    \n",
    "else:\n",
    "    selected_features = np.load('student_target_features.npy')\n",
    "    selected_metadata = np.load('student_target_metadata.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of the data\n",
    "print(\"Number of features:\", len(CME_data[0]))\n",
    "\n",
    "# positive class\n",
    "print(\"Positive class:\")\n",
    "print(\"Number of events:\", len(CME_data))\n",
    "\n",
    "# negative class\n",
    "print(\"Negative class:\")\n",
    "print(\"Number of events:\", len(no_CME_data))\n",
    "\n",
    "# Ratio: negative class to positive class\n",
    "ratio = len(no_CME_data)/len(CME_data)\n",
    "print(\"Ratio of negative class to positive class:\", ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distribution of one feature for the active regions that both flared and produced a CME (green) and for the active regions that flared but did not produce a CME (red). You can change the value of `i` in the code block below to see that some features are totally useless as there is barely any difference in the distributions for the positive and negative class. As such, we can throw such features out of our sample. It's a good idea to do some feature selection before running the SVM, so as to reduce noise (in this case, with only 18 features, there's not too much noise to begin with). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharps = ['Total unsigned flux', 'Mean gradient of total field',\n",
    "          'Mean current helicity (Bz contribution)', 'Mean photospheric magnetic free energy',\n",
    "          'Fraction of Area with Shear > 45 deg', 'Total unsigned current helicity',\n",
    "          'Mean gradient of horizontal field', 'Mean characteristic twist parameter, alpha',\n",
    "          'Mean angle of field from radial', 'Mean gradient of vertical field',\n",
    "          'Mean vertical current density', 'Total unsigned vertical current',\n",
    "          'Sum of the modulus of the net current per polarity',\n",
    "          'Total photospheric magnetic free energy density', 'Mean shear angle',\n",
    "          'Area of strong field pixels in the active region', 'Sum of flux near polarity inversion line',\n",
    "          'Absolute value of the net current helicity']\n",
    "\n",
    "i = 2\n",
    "\n",
    "# For the positive class (green)\n",
    "mu_fl = np.mean(CME_data[:, i])\n",
    "sigma_fl = np.std(CME_data[:, i])\n",
    "num_bins = 15\n",
    "n_fl, bins_fl, patches_fl = plt.hist(CME_data[:, i], num_bins, facecolor='C2', alpha=0.5,density=True)\n",
    "y_fl = scipy.stats.norm.pdf(bins_fl, mu_fl, sigma_fl)\n",
    "plt.plot(bins_fl, y_fl, 'C2--', label='positive class')\n",
    "\n",
    "# For the negative class (red)\n",
    "mu_nofl = np.mean(no_CME_data[:, i])\n",
    "sigma_nofl = np.std(no_CME_data[:, i])\n",
    "n_nofl, bins_nofl, patches_nofl = plt.hist(no_CME_data[:, i], num_bins, facecolor='C3', alpha=0.5,density=True)\n",
    "y_nofl = scipy.stats.norm.pdf(bins_nofl, mu_nofl, sigma_nofl)\n",
    "plt.plot(bins_nofl, y_nofl, 'C3--', label='negative class')\n",
    "\n",
    "plt.xlabel('Normalized '+sharps[i], fontsize=12)\n",
    "plt.ylabel('Number (normalized)', fontsize=12)\n",
    "plt.minorticks_on()\n",
    "plt.locator_params(axis='y', nbins=6)\n",
    "legend = plt.legend(loc='upper right', fontsize=12, framealpha=0.0, title='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will compute the Univariate F-score for feature selection. It is a very simple method: the F-score measures the distance between the two distributions for a given feature (inter-class distance), divided by the sum of the variances for this feature (intra-class distance). We can use the `sklearn.feature_selection` module to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the feature selection method\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "# select the number of features\n",
    "N_features = CME_data.shape[1]\n",
    "Nfl = CME_data.shape[0]\n",
    "Nnofl = no_CME_data.shape[0]\n",
    "yfl = np.ones(Nfl)\n",
    "ynofl = np.zeros(Nnofl)\n",
    "# k is the number of features\n",
    "selector = SelectKBest(f_classif, k=N_features)\n",
    "selector.fit(np.concatenate((CME_data, no_CME_data), axis=0),\n",
    "             np.concatenate((yfl, ynofl), axis=0))\n",
    "scores = selector.scores_\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not easy to interpret the scores in this way, so let's plot the results. The higher the Univariate Fisher Score, the more predictive the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "order = np.argsort(scores)\n",
    "orderedsharps = [sharps[i] for i in order]\n",
    "y_pos2 = np.arange(18)\n",
    "bars = plt.barh(y_pos2, sorted(scores/np.max(scores)), color='C3', alpha=0.8, height=0.8)\n",
    "plt.yticks(y_pos2, orderedsharps, fontsize=12)\n",
    "plt.xlabel('Normalized Fisher Score', fontsize=12)\n",
    "ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "ax.spines[['right', 'top', 'bottom']].set_visible(False) \n",
    "ax.xaxis.set_visible(False)\n",
    "\n",
    "def custom_fmt(x):\n",
    "    return '<0.01' if x < 0.01 else '%.2f' % x\n",
    "\n",
    "ax.bar_label(bars, padding=+5, color='C3', \n",
    "             fontsize=12, label_type='edge', fmt=custom_fmt,\n",
    "             fontweight='bold')\n",
    "# Add title:\n",
    "plt.title('Normalized Fisher Score for each feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: The support vector machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we initialize the support vector machine on the data. The SVM uses non-linear decision functions to map the feature space into a higher-dimensional space, where the positive and negative examples can be separated linearly by a hyperplane. <br>\n",
    "\n",
    "This is incredibly non-intuitive. But we can think of a simpler example. Suppose we had two classes: CME-producing and non-CME producing active regions. And suppose we had two features: the total flux in these regions, and the total area of these regions. We could construct a two-dimentional feature space, where we plot the flux against the area of each active region. Positive examples could be indicated by an X and negatives ones by an O. In theory, if our data behaved well, we could draw a line between these classess. <br>\n",
    "\n",
    "Since we have 18 features, the SVM constructs an 18-dimensional feature space. In this feature space, the decision boundary separating the positive and negative examples may be non-linear. As such, the algorithm then enlarges this 18-dimensional feature space (using the function indicated by the `kernel` parameter in the [`svm.SVC`](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) function) into a higher-dimensional feature space wherein it is possible to linearly separate the positive and negatives classes. There are lots of people trying to work on how to [visualize these multi-dimensional feature spaces](https://github.com/tmadl/highdimensional-decision-boundary-plot), which is an active area of research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_examples = Nfl + Nnofl\n",
    "C = 200\n",
    "gamma = 0.008\n",
    "class_weight = {1: ratio}  # After running the code once, try to use class_weight = 1 to see the difference in the results of the imbalance of the classes!\n",
    "clf = svm.SVC(C=C, gamma=gamma, kernel='rbf', class_weight=class_weight,\n",
    "              cache_size=500, max_iter=-1, shrinking=True, tol=1e-8, probability=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Stratified k-folds cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run and evaluate the performance of the SVM. There are lots of different ways to evaluate the performance of a classifier, which we discuss in Section 4 of [Bobra & Couvidat (2015)](https://arxiv.org/abs/1411.1405). We're going to choose a metric called the True Skill Score, or the TSS, which we can calculate from four quantities: true positives, true negatives, false positives, and false negatives. We prefer the TSS to all the other metrics as it is insensitive to the class imbalance ratio and thus best for comparison to other groups. The TSS is symmetrically distributed about 0: i.e., it goes from [-1, 1] where 0 represents no skill and a negative value represents a perverse prediction. Thus we are able to predict CMEs in a fashion better than randomly guessing. Here we define a confusion table to measure the performance of our binary classification: <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_table(pred, labels):\n",
    "    \"\"\"\n",
    "    computes the number of TP, TN, FP, FN events given the arrays with predictions and true labels\n",
    "    and returns the true skill score\n",
    "\n",
    "    Args:\n",
    "    pred: np array with predictions (1 for flare, 0 for nonflare)\n",
    "    labels: np array with true labels (1 for flare, 0 for nonflare)\n",
    "\n",
    "    Returns: true negative, false positive, true positive, false negative\n",
    "    \"\"\"\n",
    "    Nobs = len(pred)\n",
    "    TN = 0.\n",
    "    TP = 0.\n",
    "    FP = 0.\n",
    "    FN = 0.\n",
    "    for i in range(Nobs):\n",
    "        if (pred[i] == 0 and labels[i] == 0):\n",
    "            TN += 1\n",
    "        elif (pred[i] == 1 and labels[i] == 0):\n",
    "            FP += 1\n",
    "        elif (pred[i] == 1 and labels[i] == 1):\n",
    "            TP += 1\n",
    "        elif (pred[i] == 0 and labels[i] == 1):\n",
    "            FN += 1\n",
    "        else:\n",
    "            print(\"Error! Observation could not be classified.\")\n",
    "    return TN, FP, TP, FN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the SVM on our data and cross-validate our results. In our case, the positive sample size is quite small (both objectively and compared to the negative sample size). Therefore, we use a stratified k-folds cross-validation method, which makes k partitions of the data set and uses k-1 folds for training the SVM and 1 fold for testing the trained SVM. The stratification preserves the ratio of positive to negative examples per fold. Then we can permute over the partitions such that each partition eventually makes its way into the testing set. For each individual testing set, we can calculate a skill score. Then we can average the skill scores over the total number of testing sets. \n",
    "\n",
    "To compute the TSS, we must first select a value of k. k can be arbitrarily defined and take any value between 2 and `number_of_examples`, so we can explore this parameter space. As k approaches `number_of_examples`, the k-fold method reduces to the Leave One Out method, in which only one example is in the testing set and all other examples are in the training set. The literature suggests this method is not the best, so we can stray away from high values of k. Many studies (e.g. [Kohavi, 1995](http://web.cs.iastate.edu/~jtian/cs573/Papers/Kohavi-IJCAI-95.pdf)) recommend the stratified 10-fold cross-validation to reduce variance and bias. Here, we test their recommendation by computing the TSS using 30 k values, ranging from 2 to 32. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists to hold the TSS and standard deviation of the TSS\n",
    "array_of_avg_TSS = np.zeros([30])\n",
    "array_of_std_TSS = np.zeros([30])\n",
    "\n",
    "# xdata are the examples\n",
    "# ydata are the labels\n",
    "xdata = np.concatenate((CME_data, no_CME_data), axis=0)\n",
    "ydata = np.concatenate((np.ones(Nfl), np.zeros(Nnofl)), axis=0)\n",
    "\n",
    "# mdata contain metadata about the active region that will be useful\n",
    "# when we interpret the results using LIME\n",
    "mdata = np.concatenate((positive_class, negative_class), axis=0)\n",
    "\n",
    "# save also the confusion matrix\n",
    "confusion_matrix_ = []\n",
    "\n",
    "# compute the TSS for a variety of k ranging from 2 to 32\n",
    "# this is to see how the TSS varies as a function of k, and to test if k=10 really makes sense\n",
    "for k in range(2, 32):\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True)\n",
    "    these_TSS_for_this_k = []\n",
    "    confusion_matrix_k = []\n",
    "    for train_index, test_index in skf.split(xdata, ydata):\n",
    "        # xtrain are the examples in the training set\n",
    "        xtrain = xdata[train_index]\n",
    "        # ytrain are the labels in the training set\n",
    "        ytrain = ydata[train_index]\n",
    "        # xtest are the examples in the testing set\n",
    "        xtest = xdata[test_index]\n",
    "        # ytest are the labels in the testing set\n",
    "        ytest = ydata[test_index]    \n",
    "        # metadata useful for interpreting with LIME\n",
    "        mtrain = mdata[train_index]\n",
    "        # metadata useful for interpreting with LIME\n",
    "        mtest = mdata[test_index]\n",
    "        clf.fit(xtrain, ytrain)\n",
    "        TN, FP, TP, FN = confusion_table(clf.predict(xtest), ytest)\n",
    "        if (((TP+FN) == 0.0) or (FP+TN) == 0.0):\n",
    "            these_TSS_for_this_k.append(np.nan)\n",
    "            continue\n",
    "        else:\n",
    "            these_TSS_for_this_k.append(TP/(TP+FN) - FP/(FP+TN))\n",
    "            confusion_matrix_k.append([TN, FP, TP, FN])\n",
    "    confusion_matrix_.append(np.mean(confusion_matrix_k, axis=0))\n",
    "    \n",
    "    TSS_k = np.array(these_TSS_for_this_k)\n",
    "    array_of_avg_TSS[k-2] = np.mean(TSS_k)\n",
    "    array_of_std_TSS[k-2] = np.std(TSS_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the mean TSS per k, using the standard deviation as the error in the TSS. We see that for high values of k, the standard deviation in the TSS can be greater than the mean. These points are indicated in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))      # define the size of the figure\n",
    "\n",
    "# ascribe the data to the axes\n",
    "k = np.arange(30)+2\n",
    "for i in range(30):\n",
    "    ax.errorbar(k[i], array_of_avg_TSS[i],\n",
    "                yerr=array_of_std_TSS[i], linestyle='', color='C4')\n",
    "    ax.plot(k[i], array_of_avg_TSS[i], 'o', color=\"C4\")\n",
    "\n",
    "\n",
    "# set plot limits\n",
    "plt.xlim(xmax=32, xmin=0)\n",
    "plt.ylim(ymax=1.1, ymin=0)\n",
    "plt.minorticks_on()\n",
    "\n",
    "# label the axes and the plot\n",
    "ax.set_xlabel('k')\n",
    "ax.set_ylabel('TSS')\n",
    "plt.title(r'TSS per k using stratified k-fold cross-validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that k~10 gives us the maximum TSS with the minimum standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As such, we confirm that high k-values result in a high variance. We find it reasonable to use the stratified 10-fold cross-validation method to compute the TSS and will follow this recommendation. Therefore we report this score as our final result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the right decimals for the TSS:\n",
    "TSS = array_of_avg_TSS[9]\n",
    "TSS_std = array_of_std_TSS[9]\n",
    "print(\"The TSS is\", \"{:.2f}\".format(TSS),\"plus-minus\", \"{:.2f}\".format(TSS_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The average confusion matrix is:\")\n",
    "TN, FP, TP, FN = confusion_matrix_[9]\n",
    "confusion_matrix = np.array([TP, FN, FP, TN]).reshape(2, 2)\n",
    "print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=['CME','No CME'])\n",
    "display.plot(cmap='Blues')\n",
    "plt.title('Confusion matrix for k=10')\n",
    "\n",
    "# Now normalize the confusion matrix\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix / np.sum(confusion_matrix,axis=0), display_labels=['CME','No CME'])\n",
    "display.plot(cmap='Blues')\n",
    "plt.title('Normalized confusion matrix for k=10')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSS\n",
    "TSS_tun_list = []\n",
    "\n",
    "# Train the model\n",
    "param_grid = {'C': 10**np.arange(+0, 5, 1.0),\n",
    "              'gamma': 10**np.arange(-3, 2, 1.0)}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "for CC in param_grid['C']:\n",
    "    for GG in param_grid['gamma']:\n",
    "        clf = svm.SVC(C=CC, gamma=GG, kernel='rbf', class_weight=class_weight,\n",
    "                      cache_size=500, max_iter=-1, shrinking=True, tol=1e-8, probability=True)\n",
    "        these_TSS_for_this_k = []\n",
    "        for train_index, test_index in skf.split(xdata, ydata):\n",
    "            xtrain = xdata[train_index]\n",
    "            ytrain = ydata[train_index]\n",
    "            xtest = xdata[test_index]\n",
    "            ytest = ydata[test_index]\n",
    "            clf.fit(xtrain, ytrain)\n",
    "            TN, FP, TP, FN = confusion_table(clf.predict(xtest), ytest)\n",
    "            if (((TP+FN) == 0.0) or (FP+TN) == 0.0):\n",
    "                these_TSS_for_this_k.append(np.nan)\n",
    "                continue\n",
    "            else:\n",
    "                these_TSS_for_this_k.append(TP/(TP+FN) - FP/(FP+TN))\n",
    "        TSS_k = np.array(these_TSS_for_this_k)\n",
    "        TSS_tun_list.append(np.mean(TSS_k))\n",
    "\n",
    "TSS_tuned = np.array(TSS_tun_list).reshape(len(param_grid['C']), len(param_grid['gamma']))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.subplots_adjust(left=0.15, right=0.95, bottom=0.15, top=0.95)\n",
    "plt.imshow(TSS_tuned, interpolation='nearest', cmap='CMRmap',vmin=0, vmax=1)\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('C')\n",
    "plt.xticks(np.arange(len(param_grid['gamma'])), ['%.1e' % i for i in param_grid['gamma']])\n",
    "plt.yticks(np.arange(len(param_grid['C'])), ['%.1e' % i for i in param_grid['C']])\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('TSS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best combination of C and gamma\n",
    "best_C = param_grid['C'][np.argmax(np.max(TSS_tuned, axis=1))]\n",
    "best_gamma = param_grid['gamma'][np.argmax(np.max(TSS_tuned, axis=0))]\n",
    "print(\"The best combination of C and gamma is\", best_C, \"and\", best_gamma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look around this first estimation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSS\n",
    "TSS_tun_list = []\n",
    "\n",
    "# Train the model\n",
    "param_grid = {'C': np.logspace(np.log10(best_C/10), np.log10(best_C*10), 10),\n",
    "              'gamma': np.logspace(np.log10(best_gamma/10), np.log10(best_gamma*10), 10)}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "for CC in param_grid['C']:\n",
    "    for GG in param_grid['gamma']:\n",
    "        clf = svm.SVC(C=CC, gamma=GG, kernel='rbf', class_weight=class_weight,\n",
    "                      cache_size=500, max_iter=-1, shrinking=True, tol=1e-8, probability=True)\n",
    "        these_TSS_for_this_k = []\n",
    "        for train_index, test_index in skf.split(xdata, ydata):\n",
    "            xtrain = xdata[train_index]\n",
    "            ytrain = ydata[train_index]\n",
    "            xtest = xdata[test_index]\n",
    "            ytest = ydata[test_index]\n",
    "            clf.fit(xtrain, ytrain)\n",
    "            TN, FP, TP, FN = confusion_table(clf.predict(xtest), ytest)\n",
    "            if (((TP+FN) == 0.0) or (FP+TN) == 0.0):\n",
    "                these_TSS_for_this_k.append(np.nan)\n",
    "                continue\n",
    "            else:\n",
    "                these_TSS_for_this_k.append(TP/(TP+FN) - FP/(FP+TN))\n",
    "        TSS_k = np.array(these_TSS_for_this_k)\n",
    "        TSS_tun_list.append(np.mean(TSS_k))\n",
    "\n",
    "TSS_tuned = np.array(TSS_tun_list).reshape(len(param_grid['C']), len(param_grid['gamma']))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplots_adjust(left=0.15, right=0.95, bottom=0.15, top=0.95)\n",
    "plt.imshow(TSS_tuned, interpolation='nearest', cmap='CMRmap',vmin=0, vmax=1)\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('C')\n",
    "plt.xticks(np.arange(len(param_grid['gamma'])), ['%.1e' % i for i in param_grid['gamma']])\n",
    "plt.yticks(np.arange(len(param_grid['C'])), ['%.1e' % i for i in param_grid['C']])\n",
    "plt.locator_params(axis='x', nbins=5)\n",
    "plt.locator_params(axis='y', nbins=5)\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('TSS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best combination of C and gamma\n",
    "best_C = param_grid['C'][np.argmax(np.max(TSS_tuned, axis=1))]\n",
    "best_gamma = param_grid['gamma'][np.argmax(np.max(TSS_tuned, axis=0))]\n",
    "print(\"The best combination of C and gamma is\", best_C, \"and\", best_gamma)\n",
    "\n",
    "\n",
    "clf = svm.SVC(C=best_C, gamma=best_gamma, kernel='rbf', class_weight=class_weight,\n",
    "                cache_size=500, max_iter=-1, shrinking=True, tol=1e-8, probability=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Feature validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen that the model can predict CMEs with a high TSS using all the features. But we have seen  that some features are not very helpful in distinguishing between the positive and negative classes. But the Uni-variate Fisher Score is telling us how much each feature contributes to the prediction alone, but two features might have the same information or two with a low score might can be very informative together. \n",
    "\n",
    "There are many ways to select features, for example by forcing during the training to reduce the number of features which do not contribute to the prediction, or by using a greedy algorithm, which adds or removes features one by one. \n",
    "\n",
    "We will try a recursive feature addition algorithm, which adds features one by one and checks the TSS. We will add the feature which increases the TSS the most. This strategy does not guarantee always the best solution (as we are not checking all possible combinations), but it is fast and gives good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sequential feature selection: adding features one by one\n",
    "\n",
    "total_features = CME_data.shape[1]\n",
    "\n",
    "best_combination = []\n",
    "TSS_for_best_combination = []\n",
    "for combination in range(1, total_features+1):\n",
    "    TSS_for_this_combination = []\n",
    "    # features_to_use is the index saved in best_combination and the index of the feature we are testing\n",
    "    for feature_to_test in range(total_features):\n",
    "        if feature_to_test in best_combination:\n",
    "            TSS_for_this_combination.append(0.0)\n",
    "            continue\n",
    "        features_to_use = best_combination.copy()\n",
    "        features_to_use.append(feature_to_test)\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "        these_TSS_for_this_k = []\n",
    "        for train_index, test_index in skf.split(xdata, ydata):\n",
    "            xtrain = xdata[train_index][:, features_to_use]\n",
    "            ytrain = ydata[train_index]\n",
    "            xtest = xdata[test_index][:, features_to_use]        \n",
    "            mtest = mdata[test_index]\n",
    "            ytest = ydata[test_index]\n",
    "            clf.fit(xtrain, ytrain)\n",
    "            TN, FP, TP, FN = confusion_table(clf.predict(xtest), ytest)\n",
    "            these_TSS_for_this_k.append(TP/(TP+FN) - FP/(FP+TN))\n",
    "        TSS = np.mean(these_TSS_for_this_k)\n",
    "        \n",
    "        TSS_for_this_combination.append(TSS)\n",
    "    best_combination.append(np.argmax(TSS_for_this_combination))\n",
    "    TSS_for_best_combination.append(np.max(TSS_for_this_combination))\n",
    "    print(\"The best combination so far is\", best_combination, \"with a TSS of\", \"{:.2f}\".format(np.max(TSS_for_this_combination)), \n",
    "          \"where addition had a score of\", \"{:.2f}\".format(selector.scores_[np.argmax(TSS_for_this_combination)]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best combination of features with the names:\n",
    "best_combination_names = [sharps[i] for i in best_combination]\n",
    "for i in range(len(best_combination)):\n",
    "    print(\"Feature\", best_combination[i], \":\", best_combination_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An important trend we can already see is that as we start adding too many features, the TSS starts to decrease.\n",
    "plt.plot(np.arange(1, total_features+1), TSS_for_best_combination, 'o-', color='C4')\n",
    "plt.xlabel('Number of features')\n",
    "plt.ylabel('TSS')\n",
    "plt.title('TSS as a function of the number of features')\n",
    "plt.xticks(np.arange(1, total_features+1))\n",
    "plt.ylim(ymax=1.0, ymin=0)\n",
    "plt.locator_params(axis='x', nbins=9)\n",
    "plt.minorticks_on()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Index of the features that are selected\n",
    "label_of_features = []\n",
    "for feature in range(18):\n",
    "    label_of_features.append(best_combination.index(feature))\n",
    "\n",
    "norder = np.argsort(label_of_features)[::-1]\n",
    "norderedsharps = [sharps[i] for i in norder]\n",
    "nscores = [selector.scores_[i] for i in norder]\n",
    "y_pos2 = np.arange(18)\n",
    "bars = plt.barh(y_pos2, nscores/np.max(scores), color='C3', alpha=0.8, height=0.8)\n",
    "plt.yticks(y_pos2, norderedsharps, fontsize=12)\n",
    "plt.xlabel('Normalized Fisher Score', fontsize=12)\n",
    "ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "ax.spines[['right', 'top', 'bottom']].set_visible(False) \n",
    "ax.xaxis.set_visible(False)\n",
    "\n",
    "plt.title('Normalized Fisher Score, ordered by feature selection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Interpretable Model-Agnostic Explanations (LIME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine-learning is a powerful technique that can help us predict CMEs. However, our goal is not only to predict CMEs, but also to quantitatively understand which signatures indicate the imminent eruption of a CME. But the practical successes of machine-learning algorithms are often not matched by successes in understanding, and this has become an issue within the machine-learning community ([Rahimi and Recht, 2017](http://www.argmin.net/2017/12/11/alchemy-addendum/)).\n",
    "\n",
    "The SVM is a good model to start with, because it is (relatively) simple and we can use the Univariate Fisher Score to identify the most predictive features. But it would also be useful to figure out why each individual active region was classed as positive or negative. To do this, we can use a tool called [LIME](https://github.com/marcotcr/lime) (or Local Interpretable Model-Agnostic Explanations). <br>\n",
    "\n",
    "First, we initialize the LIME explainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    xtrain, feature_names=sharps, class_names=['CME', 'no CME'], discretize_continuous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the explainer to explain its choice for a particular active region. To do this, the LIME module generates neighborhood data by randomly perturbing the values of the features associated with this active region. If, for any given feature, this perturbation does not change the outcome of the prediction, this feature isn't useful along the perturbed dimension. If, for any given feature, the perturbation does change the outcome of the prediction, this feature is useful along the perturbed dimension. Thus the explainer can determine which features are useful under which conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(0, xtest.shape[0])\n",
    "exp = explainer.explain_instance(xtest[i], clf.predict_proba, num_features=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize the results. The bottom left panel shows the probabilities assigned to this particular example (which are computed by the SVM via the `probability=True` parameter). The right panel plots the weights per feature (and indicates the values of these weights at the end of each horizontal bar). The text describes the conditions under which this feature  is predictive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Here is the prediction explanation for NOAA Active Region\",\n",
    "      mtest[i][1], \"(HARPNUM \", mtest[i][0], \"),\\n which produced a\", mtest[i][2], \"class flare on\", mtest[i][3], \".\")\n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the same information in words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_list = exp.as_list()\n",
    "for kk in range(len(explained_list)):\n",
    "    if (explained_list[kk][1]) < 0:\n",
    "        feature_sign = 'no CME'\n",
    "    else:\n",
    "        feature_sign = 'CME'\n",
    "    print(\"If the condition\", explained_list[kk][0], \"does not apply, \", \"\\n the model predicts\",\n",
    "          feature_sign, \"with a model weight of\", abs(explained_list[kk][1]), \".\")\n",
    "    \n",
    "\n",
    "# Remember that the features are normalized, so these values are not the actual values of the features. You should re-scale them to get the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_index = lambda x: sharps.index(x)\n",
    "\n",
    "feature_to_test = 'Mean vertical current density'\n",
    "print('Changing the feature:', feature_to_test)\n",
    "temp = xtest[i].copy()\n",
    "print('Current value:',temp[feature_index(feature_to_test)])\n",
    "print('P(CME) before:', clf.predict_proba(temp.reshape(1,-1))[0,0])\n",
    "temp[feature_index(feature_to_test)] = 0.0\n",
    "print('P(CME) after:', clf.predict_proba(temp.reshape(1,-1))[0,0])\n",
    "print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Did the prediction work?\n",
    "print('Did the prediction work?')\n",
    "print('The predictor found that the region is likely to', 'not have a CME.' if clf.predict(xtest[i].reshape(1,-1))[0] == 0 else 'have a CME.')\n",
    "\n",
    "# Let's check the metadata:\n",
    "if mtest[i] in positive_class:\n",
    "    print('And the flare had a CME associated with it.')\n",
    "else:\n",
    "    print('And the flare did not have a CME associated with it.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the predictor to analyze new observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_index = 0\n",
    "\n",
    "my_features = selected_features[student_index]\n",
    "my_metadata = selected_metadata[student_index]\n",
    "\n",
    "# Now it your turn to investigate your AR:\n",
    "print(\"Investigating NOAA Active Region\", my_metadata[1], \"(HARPNUM\", my_metadata[0], \"),\\n which produced a\", my_metadata[2], \"class flare on\", my_metadata[3], \".\")\n",
    "\n",
    "# Quick check that there is similar data point in the full dataset:\n",
    "if my_metadata in positive_class:\n",
    "    print(\"This is a positive class example.\")\n",
    "elif my_metadata in negative_class:\n",
    "    print(\"This is a negative class example.\")\n",
    "else:\n",
    "    print(\"This is not in the full dataset.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
